---
title: "Project week 13"
output: html_document
---

# 1. Defining our data

The dataset consists of 10 numerical and 8 categorical attributes. The 'Revenue' attribute can be used as the class label.

"Administrative", "Administrative Duration", "Informational", "Informational Duration", "Product Related" and "Product Related Duration" represents the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. 

The values of these features are derived from the URL information of the pages visited by the user and updated in real-time when a user takes an action, e.g. moving from one page to another. 

The "Bounce Rate", "Exit Rate" and "Page Value" features represent the metrics measured by "Google Analytics" for each page in the e-commerce site. 

The value of the "Bounce Rate" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave ("bounce") without triggering any other requests to the analytics server during that session. 

The value of the "Exit Rate" feature for a specific web page is calculated as for all pageviews to the page, the percentage that was the last in the session.

The "Page Value" feature represents the average value for a web page that a user visited before completing an e-commerce transaction. 

The "Special Day" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which the sessions are more likely to be finalized with the transaction. 

The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentine’s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8. 

The dataset also includes the operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year

# Solution
Applying unsupervised learning models such as K-means clustering and Hierachical clustering
to our dataset.

## Defining our question
### Specifying our question
To enable Kira Plastinina, a Russian brand to understand customer behavior from collected data and learning characteristics of customer groups

### Defining our metric of success
To be able to identify most customer groups and their characteristics successfully

### Understanding the context
Kira Plastinina is a Russian brand that is sold through a defunct chain of retail stores in Russia, China, Philippines, Ukraine, Kazakhstan, Belarus and Armenia.
Our strategies are meant to inform the team in formulating the marketing and sales strategies of the brand.


### Recording the experimental design
1.Problem Definition
2.Data sourcing
3. Checking the data
4. Data Cleaning
5. Exploratory Data Analysis
6. Implementing the solution
7. Challenge the solution
8. Follow up questions

### Data Relevance
The data provided by the brand is relevant to our analysis.

##Reading our data
### Importing our libraries

library(modelr)
library(tidyverse)

# Loading our dataset
online_shoppers_intention

## Checking our data
### Converting our data to a dataframe
### Reading the first 6 rows of our data

df <- data.frame(online_shoppers_intention)
head(df)

### Reading the last 6 rows of our data
tail(df)

### Obtaining the summary of our data
summary(df)

### Determining the number of records in our data.
dim(df)

## Tidying our data
### Checking for any null values
is.na(df)

### Counting the number of missing values
colSums(is.na(df))

### Dropping missing values in our data
data <- na.omit(df)

### Checking for any more missing values
colSums(is.na(data))

### Checking the column names in our data
colnames(data)

### Checking for any duplicated values
Duplicate <- data[duplicated(data),]
Duplicate

### Dropping duplicated values in our data by allocating the unique values to a new dataframe.
df <- unique(data)
df

### Checking the number of rows remaining.
dim(df)

### Reading our data
head(df)

### Assigning our columns to variables

admin <- df$Administrative
addur <- df$Administrative_Duration
info <- df$Informational
indur <- df$Informational_Duration
prodr <- df$ProductRelated
proddur <- df$ProductRelated_Duration
brates <- df$BounceRates
erates <- df$ExitRates
pgv <- df$PageValues
spday <- df$SpecialDay
opsy <- df$OperatingSystems
brow <- df$Browser
reg <- df$Region
traff <- df$TrafficType


## Using boxplot to check for outliers

boxplot(admin)
boxplot(addur)
boxplot(info)
boxplot(indur)
boxplot(prodr)
boxplot(proddur)
boxplot(brates)
boxplot(erates)
boxplot(pgv)
boxplot(spday)
boxplot(opsy)
boxplot(brow)
boxplot(reg)
boxplot(traff)

### From our columns, we can see that our data is filled with outliers, which if removed may greatly affect 

## Univariate Analysis
### Loading our datasets
head(df)

### Calculating the mean for our numerical variables
### Product_related
prodr_mean <- mean(prodr)
prodr_mean

### Administration
admin_mean <- mean(admin)
admin_mean

### Product_Related Duration
proddur_mean <- mean(proddur)
proddur_mean

### Bounce Rates
brates_mean <- mean(brates)
brates_mean

### Operating Systems
opsy_mean <- mean(opsy)
opsy_mean

### Browser
brow_mean <- mean(brow)
brow_mean

### Exit Rates
erates_mean <- mean(erates)
erates_mean

### Region
reg_mean <- mean(reg)
reg_mean

### Creating a function(getmode) to enable us to calculate the modes of our columns
getmode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

### Administration
admin_mode <- getmode(admin)
admin_mode

### Product_Related Duration
proddur_mode <- getmode(proddur)
proddur_mode

## Operational Systems
opsy_mode <- getmode(opsy)
opsy_mode

### TrafficType
traff_mode <- getmode(traff)
traff_mode

### Browser
brow_mode <- getmode(brow)
brow_mode

## Bivariate and Multivariate Analysis
### Previewing our data
head(df)

### Determining the correlation between our numeric columns
### Correlation between Administration and Administration Duration
cor(admin, addur)

### Correlation between Information and Information Duration
cor(info, indur)

### Correlation between Browser and Region
cor(brow, reg)

### Traffic Type and Region
cor(traff, reg)

### Bounce rates and Exit rates
cor(brates, erates)

### ProductRelated and ProductRelated_Duration
cor(prodr, proddur)

### PageValues and ProductRelated
cor(pgv, prodr)

### ProductRelated and TrafficType
cor(prodr, traff)

### SpecialDay and Bounce Rates
cor(spday, brates)

Determining the covariance between numerical variables. High covariance between columns shows similar behaviour 
while low variance shows opposite behavior

### ProductRelated and ProductRelated_Duration
cov(prodr, proddur)

This shows very high covariance between both columns

### Information and Information_Duration.
cov(info, indur)

There is also high covariance between these two columns

### Bounce rates and Exit Rates
cov(brates, erates)

There is extremely low variance between these two columns

### Administration and Information
cov(admin, info)

These columns have low covariance.

### Plotting scatter plots for data visualisation.
plot(admin, addur, xlab="Administration", ylab = "Admin Duration")

plot(brow, brates, xlab = "Bounce rates", ylab = "Browser")

plot(opsy, traff, xlab = "Operating System", ylab = "Traffic")

plot(proddur, prodr, xlab = "Product Duration", ylab = "Product related")

plot(indur, info, xlab = "Information Duration", ylab = "Information")


## Implementing the solution
### Loading our dataset
head(df)

We will use K-mean clustering to build our model

### Determining the unique values in our VisitorType column
unique(df$VisitorType)

### Converting our categorical columns to variables
df$VisitorType <- factor(df$VisitorType, levels = c("Returning_Visitor", "New_Visitor", "Other"), labels = c(0,1,2))
unique(df$VisitorType)

df$Weekend <- factor(df$Weekend, levels = c("FALSE", "TRUE"), labels = c(0,1))
unique(df$Weekend)

df$Month <- factor(df$Month, levels = c("Feb","Mar","May","Oct","June","Jul","Aug","Nov","Sep","Dec"), labels = c(1,2,3,4,5,6,7,8,9,10))
unique(df$Month)

### Allocating our Revenue column as our class label
df.new <- df[, c(1:17)]
df.class<- df$Revenue

### Previewing our class label
head(df.class)

### Creating a function(normalize) to normalize our data columns
normalize <- function(x){
  return ((x-min(x)) / (max(x)-min(x)))
}

### Once the function has been created, then we apply it on our columns
df.new$Administrative <- normalize(df.new$Administrative)
df.new$Administrative_Duration <- normalize(df.new$Administrative_Duration)
df.new$Informational <- normalize(df.new$Informational)
df.new$Informational_Duration <- normalize(df.new$Informational_Duration)
df.new$ProductRelated <- normalize(df.new$ProductRelated)
df.new$ProductRelated_Duration <- normalize(df.new$ProductRelated_Duration)
df.new$BounceRates <- normalize(df.new$BounceRates)
df.new$ExitRates <- normalize(df.new$ExitRates)
df.new$PageValues <- normalize(df.new$PageValues)
df.new$SpecialDay <- normalize(df.new$SpecialDay)
df.new$Month <- normalize(df.new$Month)
df.new$OperatingSystems <- normalize(df.new$OperatingSystems)
df.new$Browser <- normalize(df.new$Browser)
df.new$Region <- normalize(df.new$Region)
df.new$TrafficType <- normalize(df.new$TrafficType)
df.new$VisitorType <- normalize(df.new$VisitorType)
df.new$Weekend <- normalize(df.new$Weekend)

### Previewing the normalized set of data
head(df.new)

### Applying the K-means algorithm with the number of clusters to be used 
result<- kmeans(df.new,2)

### Previewing the number of records in each cluster
result$size

### Getting the value of cluster center datapoint value(2 centers for k=2)
result$centers

### Getting the cluster vector that shows the cluster where each record falls
result$cluster

### Verifying the results of clustering
par(mfrow = c(2,2), mar = c(5,4,2,2))

### Plotting to see the first and second data points have been distributed in clusters
plot(df.new[c(1,2)], col = result$cluster)

### Plotting to see how our columns have been distributed originally as per "class" attribute in dataset
plot(df.new[c(1,2)], col = df.class)

plot(df.new[c(3,4)], col = result$cluster)
plot(df.new[c(3,4)], col = df.class)

plot(df.new[c(5,6)], col = result$cluster)
plot(df.new[c(5,6)], col = df.class)

plot(df.new[c(7,8)], col = result$cluster)
plot(df.new[c(7,8)], col = df.class)

plot(df.new[c(9,10)], col = result$cluster)
plot(df.new[c(9,10)], col = df.class)

plot(df.new[c(11,12)], col = result$cluster)
plot(df.new[c(11,12)], col = df.class)

plot(df.new[c(13,14)], col = result$cluster)
plot(df.new[c(13,14)], col = df.class)

plot(df.new[c(15,16)], col = result$cluster)
plot(df.new[c(15,16)], col = df.class)

### Plotting table values for the clusters
table(result$cluster, df.class)

## Hierachical Clustering
### Loading our data
head(df)

### Converting our categorical columns to variables
df$VisitorType <- factor(df$VisitorType, levels = c("Returning_Visitor", "New_Visitor", "Other"), labels = c(0,1,2))
unique(df$VisitorType)

df$Weekend <- factor(df$Weekend, levels = c("FALSE", "TRUE"), labels = c(0,1))
unique(df$Weekend)

df$Month <- factor(df$Month, levels = c("Feb","Mar","May","Oct","June","Jul","Aug","Nov","Sep","Dec"), labels = c(1,2,3,4,5,6,7,8,9,10))
unique(df$Month)

df$Revenue <- factor(df$Revenue, levels = c("FALSE", "TRUE"), labels = c(0,1))
unique(df$Revenue)

###We will perform descriptive analysis for our data
stats <- data.frame(
  Min = apply(df, 2, min),    # minimum
  Med = apply(df, 2, median), # median
  Mean = apply(df, 2, mean),  # mean
  SD = apply(df, 2, sd),      # Standard deviation
  Max = apply(df, 2, max)     # Maximum
)
stats <- round(stats, 1)
head(stats)

#### We have noticed that our data has different values for the min and missing values in our mean column
#### This has been attributed to different unit of measurement.
#### They must be standardized (i.e., scaled) to make them comparable. 
#### This means transforming the variables such that they have mean zero and standard deviation one
df <- scale(df)
head(df)

### We now use the R function hclust() for hierarchical clustering
### First we use the dist() function to compute the Euclidean distance between observations

d <- dist(df, method = "euclidean")

### We then hierarchical clustering using the Ward's method
res.hc <- hclust(d, method = "ward.D2" )

### Lastly, we plot the obtained dendrogram
plot(res.hc, cex = 0.6, hang = -1)


## Challenging the solution
From our observations made during analysis, hierachial clustering gives better results than using K means clustering
since it is easier to follow and see the type of clusters created. The visual, although crowded, shows better distinct patterns within our data.

## Follow-up questions

### i) Did we have the right data?
We believe we had the right data but with a few issues during data collection that leads to getting incorrect observations.
We believe the presence of outliers may also have influenced our results

### ii) Did we need more data?
Our data would have used more information regarding the duration and the quality of service they received, whether the customer was pleased or disappointed in the brands.

### Did we have the right question?
We believe that we had the right question to help us in our analysis. 
